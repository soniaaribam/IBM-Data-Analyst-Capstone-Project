{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform data wrangling tasks to prepare raw data for analysis. Data wrangling involves cleaning, transforming, and organizing data into a structured format suitable for analysis. This lab focuses on tasks like identifying inconsistencies, encoding categorical variables, and feature transformation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing this lab, you will be able to:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify and remove inconsistent data entries.\n",
    "\n",
    "- Encode categorical variables for analysis.\n",
    "\n",
    "- Handle missing values using multiple imputation strategies.\n",
    "\n",
    "- Apply feature scaling and transformation techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intsall the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m154.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m151.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.3 pandas-2.2.3 tzdata-2025.1\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.56.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m163.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.56.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m129.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m127.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.1 pillow-11.1.0 pyparsing-3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import the necessary module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1.1 Import necessary libraries and load the dataset.</h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the dataset is loaded correctly by displaying the first few rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Explore the Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.1 Summarize the dataset by displaying the column data types, counts, and missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "    ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"First 5 rows of the dataset:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Data Types:\n",
      " ResponseId               int64\n",
      "MainBranch              object\n",
      "Age                     object\n",
      "Employment              object\n",
      "RemoteWork              object\n",
      "                        ...   \n",
      "JobSatPoints_11        float64\n",
      "SurveyLength            object\n",
      "SurveyEase              object\n",
      "ConvertedCompYearly    float64\n",
      "JobSat                 float64\n",
      "Length: 114, dtype: object\n",
      "\n",
      "Missing Values per Column:\n",
      " ResponseId                 0\n",
      "MainBranch                 0\n",
      "Age                        0\n",
      "Employment                 0\n",
      "RemoteWork             10631\n",
      "                       ...  \n",
      "JobSatPoints_11        35992\n",
      "SurveyLength            9255\n",
      "SurveyEase              9199\n",
      "ConvertedCompYearly    42002\n",
      "JobSat                 36311\n",
      "Length: 114, dtype: int64\n",
      "\n",
      "Summary Statistics:\n",
      "          ResponseId      CompTotal       WorkExp  JobSatPoints_1  \\\n",
      "count  65437.000000   3.374000e+04  29658.000000    29324.000000   \n",
      "mean   32719.000000  2.963841e+145     11.466957       18.581094   \n",
      "std    18890.179119  5.444117e+147      9.168709       25.966221   \n",
      "min        1.000000   0.000000e+00      0.000000        0.000000   \n",
      "25%    16360.000000   6.000000e+04      4.000000        0.000000   \n",
      "50%    32719.000000   1.100000e+05      9.000000       10.000000   \n",
      "75%    49078.000000   2.500000e+05     16.000000       22.000000   \n",
      "max    65437.000000  1.000000e+150     50.000000      100.000000   \n",
      "\n",
      "       JobSatPoints_4  JobSatPoints_5  JobSatPoints_6  JobSatPoints_7  \\\n",
      "count    29393.000000    29411.000000    29450.000000     29448.00000   \n",
      "mean         7.522140       10.060857       24.343232        22.96522   \n",
      "std         18.422661       21.833836       27.089360        27.01774   \n",
      "min          0.000000        0.000000        0.000000         0.00000   \n",
      "25%          0.000000        0.000000        0.000000         0.00000   \n",
      "50%          0.000000        0.000000       20.000000        15.00000   \n",
      "75%          5.000000       10.000000       30.000000        30.00000   \n",
      "max        100.000000      100.000000      100.000000       100.00000   \n",
      "\n",
      "       JobSatPoints_8  JobSatPoints_9  JobSatPoints_10  JobSatPoints_11  \\\n",
      "count    29456.000000    29456.000000     29450.000000     29445.000000   \n",
      "mean        20.278165       16.169432        10.955713         9.953948   \n",
      "std         26.108110       24.845032        22.906263        21.775652   \n",
      "min          0.000000        0.000000         0.000000         0.000000   \n",
      "25%          0.000000        0.000000         0.000000         0.000000   \n",
      "50%         10.000000        5.000000         0.000000         0.000000   \n",
      "75%         25.000000       20.000000        10.000000        10.000000   \n",
      "max        100.000000      100.000000       100.000000       100.000000   \n",
      "\n",
      "       ConvertedCompYearly        JobSat  \n",
      "count         2.343500e+04  29126.000000  \n",
      "mean          8.615529e+04      6.935041  \n",
      "std           1.867570e+05      2.088259  \n",
      "min           1.000000e+00      0.000000  \n",
      "25%           3.271200e+04      6.000000  \n",
      "50%           6.500000e+04      7.000000  \n",
      "75%           1.079715e+05      8.000000  \n",
      "max           1.625660e+07     10.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nColumn Data Types:\\n\", df.dtypes)\n",
    "\n",
    "print(\"\\nMissing Values per Column:\\n\", df.isnull().sum())\n",
    "\n",
    "print(\"\\nSummary Statistics:\\n\", df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2.2 Generate basic statistics for numerical columns.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic Statistics for Numerical Columns:\n",
      "          ResponseId      CompTotal       WorkExp  JobSatPoints_1  \\\n",
      "count  65437.000000   3.374000e+04  29658.000000    29324.000000   \n",
      "mean   32719.000000  2.963841e+145     11.466957       18.581094   \n",
      "std    18890.179119  5.444117e+147      9.168709       25.966221   \n",
      "min        1.000000   0.000000e+00      0.000000        0.000000   \n",
      "25%    16360.000000   6.000000e+04      4.000000        0.000000   \n",
      "50%    32719.000000   1.100000e+05      9.000000       10.000000   \n",
      "75%    49078.000000   2.500000e+05     16.000000       22.000000   \n",
      "max    65437.000000  1.000000e+150     50.000000      100.000000   \n",
      "\n",
      "       JobSatPoints_4  JobSatPoints_5  JobSatPoints_6  JobSatPoints_7  \\\n",
      "count    29393.000000    29411.000000    29450.000000     29448.00000   \n",
      "mean         7.522140       10.060857       24.343232        22.96522   \n",
      "std         18.422661       21.833836       27.089360        27.01774   \n",
      "min          0.000000        0.000000        0.000000         0.00000   \n",
      "25%          0.000000        0.000000        0.000000         0.00000   \n",
      "50%          0.000000        0.000000       20.000000        15.00000   \n",
      "75%          5.000000       10.000000       30.000000        30.00000   \n",
      "max        100.000000      100.000000      100.000000       100.00000   \n",
      "\n",
      "       JobSatPoints_8  JobSatPoints_9  JobSatPoints_10  JobSatPoints_11  \\\n",
      "count    29456.000000    29456.000000     29450.000000     29445.000000   \n",
      "mean        20.278165       16.169432        10.955713         9.953948   \n",
      "std         26.108110       24.845032        22.906263        21.775652   \n",
      "min          0.000000        0.000000         0.000000         0.000000   \n",
      "25%          0.000000        0.000000         0.000000         0.000000   \n",
      "50%         10.000000        5.000000         0.000000         0.000000   \n",
      "75%         25.000000       20.000000        10.000000        10.000000   \n",
      "max        100.000000      100.000000       100.000000       100.000000   \n",
      "\n",
      "       ConvertedCompYearly        JobSat  \n",
      "count         2.343500e+04  29126.000000  \n",
      "mean          8.615529e+04      6.935041  \n",
      "std           1.867570e+05      2.088259  \n",
      "min           1.000000e+00      0.000000  \n",
      "25%           3.271200e+04      6.000000  \n",
      "50%           6.500000e+04      7.000000  \n",
      "75%           1.079715e+05      8.000000  \n",
      "max           1.625660e+07     10.000000  \n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "print(\"\\nBasic Statistics for Numerical Columns:\\n\", df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Identifying and Removing Inconsistencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.1 Identify inconsistent or irrelevant entries in specific columns (e.g., Country).</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States of America'\n",
      " 'United Kingdom of Great Britain and Northern Ireland' 'Canada' 'Norway'\n",
      " 'Uzbekistan' 'Serbia' 'Poland' 'Philippines' 'Bulgaria' 'Switzerland'\n",
      " 'India' 'Germany' 'Ireland' 'Italy' 'Ukraine' 'Australia' 'Brazil'\n",
      " 'Japan' 'Austria' 'Iran, Islamic Republic of...' 'France' 'Saudi Arabia'\n",
      " 'Romania' 'Turkey' 'Nepal' 'Algeria' 'Sweden' 'Netherlands' 'Croatia'\n",
      " 'Pakistan' 'Czech Republic' 'Republic of North Macedonia' 'Finland'\n",
      " 'Slovakia' 'Russian Federation' 'Greece' 'Israel' 'Belgium' 'Mexico'\n",
      " 'United Republic of Tanzania' 'Hungary' 'Argentina' 'Portugal'\n",
      " 'Sri Lanka' 'Latvia' 'China' 'Singapore' 'Lebanon' 'Spain' 'South Africa'\n",
      " 'Lithuania' 'Viet Nam' 'Dominican Republic' 'Indonesia' 'Kosovo'\n",
      " 'Morocco' 'Taiwan' 'Georgia' 'San Marino' 'Tunisia' 'Bangladesh'\n",
      " 'Nigeria' 'Liechtenstein' 'Denmark' 'Ecuador' 'Malaysia' 'Albania'\n",
      " 'Azerbaijan' 'Chile' 'Ghana' 'Peru' 'Bolivia' 'Egypt' 'Luxembourg'\n",
      " 'Montenegro' 'Cyprus' 'Paraguay' 'Kazakhstan' 'Slovenia' 'Jordan'\n",
      " 'Venezuela, Bolivarian Republic of...' 'Costa Rica' 'Jamaica' 'Thailand'\n",
      " 'Nicaragua' 'Myanmar' 'Republic of Korea' 'Rwanda'\n",
      " 'Bosnia and Herzegovina' 'Benin' 'El Salvador' 'Zimbabwe' 'Afghanistan'\n",
      " 'Estonia' 'Malta' 'Uruguay' 'Belarus' 'Colombia' 'Republic of Moldova'\n",
      " 'Isle of Man' 'Nomadic' 'New Zealand' 'Palestine' 'Armenia'\n",
      " 'United Arab Emirates' 'Maldives' 'Ethiopia' 'Fiji' 'Guatemala' 'Uganda'\n",
      " 'Turkmenistan' 'Mauritius' 'Kenya' 'Cuba' 'Gabon' 'Bahamas' 'South Korea'\n",
      " 'Iceland' 'Honduras' 'Hong Kong (S.A.R.)'\n",
      " \"Lao People's Democratic Republic\" 'Mongolia' 'Cambodia' 'Madagascar'\n",
      " 'Angola' 'Democratic Republic of the Congo' 'Syrian Arab Republic' 'Iraq'\n",
      " 'Namibia' 'Senegal' 'Kyrgyzstan' 'Zambia' 'Swaziland' \"Côte d'Ivoire\"\n",
      " 'Kuwait' 'Tajikistan' 'Burundi' 'Trinidad and Tobago' 'Mauritania'\n",
      " 'Sierra Leone' 'Panama' 'Somalia' 'North Korea' 'Dominica' 'Guyana'\n",
      " 'Togo' 'Oman' 'Barbados' 'Andorra'\n",
      " \"Democratic People's Republic of Korea\" 'Qatar' 'Sudan' 'Cameroon'\n",
      " 'Papua New Guinea' 'Bahrain' 'Yemen' 'Malawi' 'Burkina Faso'\n",
      " 'Congo, Republic of the...' 'Botswana' 'Guinea-Bissau' 'Mozambique'\n",
      " 'Central African Republic' 'Equatorial Guinea' 'Suriname' 'Belize'\n",
      " 'Libyan Arab Jamahiriya' 'Cape Verde' 'Brunei Darussalam' 'Bhutan'\n",
      " 'Guinea' 'Niger' 'Antigua and Barbuda' 'Mali' 'Samoa' 'Lesotho'\n",
      " 'Saint Kitts and Nevis' 'Monaco' 'Micronesia, Federated States of...'\n",
      " 'Haiti' nan 'Nauru' 'Liberia' 'Chad' 'Djibouti' 'Solomon Islands']\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "print(df[\"Country\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "United States of America                                11095\n",
      "Germany                                                  4947\n",
      "India                                                    4231\n",
      "United Kingdom of Great Britain and Northern Ireland     3224\n",
      "Ukraine                                                  2672\n",
      "                                                        ...  \n",
      "Micronesia, Federated States of...                          1\n",
      "Nauru                                                       1\n",
      "Chad                                                        1\n",
      "Djibouti                                                    1\n",
      "Solomon Islands                                             1\n",
      "Name: count, Length: 185, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Country\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Country\"].notna()] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3.2 Standardize entries in columns like Country or EdLevel by mapping inconsistent values to a consistent format.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States of America'\n",
      " 'United Kingdom of Great Britain and Northern Ireland' 'Canada' 'Norway'\n",
      " 'Uzbekistan' 'Serbia' 'Poland' 'Philippines' 'Bulgaria' 'Switzerland'\n",
      " 'India' 'Germany' 'Ireland' 'Italy' 'Ukraine' 'Australia' 'Brazil'\n",
      " 'Japan' 'Austria' 'Iran, Islamic Republic of...' 'France' 'Saudi Arabia'\n",
      " 'Romania' 'Turkey' 'Nepal' 'Algeria' 'Sweden' 'Netherlands' 'Croatia'\n",
      " 'Pakistan' 'Czech Republic' 'Republic of North Macedonia' 'Finland'\n",
      " 'Slovakia' 'Russian Federation' 'Greece' 'Israel' 'Belgium' 'Mexico'\n",
      " 'United Republic of Tanzania' 'Hungary' 'Argentina' 'Portugal'\n",
      " 'Sri Lanka' 'Latvia' 'China' 'Singapore' 'Lebanon' 'Spain' 'South Africa'\n",
      " 'Lithuania' 'Viet Nam' 'Dominican Republic' 'Indonesia' 'Kosovo'\n",
      " 'Morocco' 'Taiwan' 'Georgia' 'San Marino' 'Tunisia' 'Bangladesh'\n",
      " 'Nigeria' 'Liechtenstein' 'Denmark' 'Ecuador' 'Malaysia' 'Albania'\n",
      " 'Azerbaijan' 'Chile' 'Ghana' 'Peru' 'Bolivia' 'Egypt' 'Luxembourg'\n",
      " 'Montenegro' 'Cyprus' 'Paraguay' 'Kazakhstan' 'Slovenia' 'Jordan'\n",
      " 'Venezuela, Bolivarian Republic of...' 'Costa Rica' 'Jamaica' 'Thailand'\n",
      " 'Nicaragua' 'Myanmar' 'Republic of Korea' 'Rwanda'\n",
      " 'Bosnia and Herzegovina' 'Benin' 'El Salvador' 'Zimbabwe' 'Afghanistan'\n",
      " 'Estonia' 'Malta' 'Uruguay' 'Belarus' 'Colombia' 'Republic of Moldova'\n",
      " 'Isle of Man' 'Nomadic' 'New Zealand' 'Palestine' 'Armenia'\n",
      " 'United Arab Emirates' 'Maldives' 'Ethiopia' 'Fiji' 'Guatemala' 'Uganda'\n",
      " 'Turkmenistan' 'Mauritius' 'Kenya' 'Cuba' 'Gabon' 'Bahamas' 'South Korea'\n",
      " 'Iceland' 'Honduras' 'Hong Kong (S.A.R.)'\n",
      " \"Lao People's Democratic Republic\" 'Mongolia' 'Cambodia' 'Madagascar'\n",
      " 'Angola' 'Democratic Republic of the Congo' 'Syrian Arab Republic' 'Iraq'\n",
      " 'Namibia' 'Senegal' 'Kyrgyzstan' 'Zambia' 'Swaziland' \"Côte d'Ivoire\"\n",
      " 'Kuwait' 'Tajikistan' 'Burundi' 'Trinidad and Tobago' 'Mauritania'\n",
      " 'Sierra Leone' 'Panama' 'Somalia' 'North Korea' 'Dominica' 'Guyana'\n",
      " 'Togo' 'Oman' 'Barbados' 'Andorra'\n",
      " \"Democratic People's Republic of Korea\" 'Qatar' 'Sudan' 'Cameroon'\n",
      " 'Papua New Guinea' 'Bahrain' 'Yemen' 'Malawi' 'Burkina Faso'\n",
      " 'Congo, Republic of the...' 'Botswana' 'Guinea-Bissau' 'Mozambique'\n",
      " 'Central African Republic' 'Equatorial Guinea' 'Suriname' 'Belize'\n",
      " 'Libyan Arab Jamahiriya' 'Cape Verde' 'Brunei Darussalam' 'Bhutan'\n",
      " 'Guinea' 'Niger' 'Antigua and Barbuda' 'Mali' 'Samoa' 'Lesotho'\n",
      " 'Saint Kitts and Nevis' 'Monaco' 'Micronesia, Federated States of...'\n",
      " 'Haiti' 'Nauru' 'Liberia' 'Chad' 'Djibouti' 'Solomon Islands']\n",
      "['United States of America'\n",
      " 'United Kingdom of Great Britain and Northern Ireland' 'Canada' 'Norway'\n",
      " 'Uzbekistan' 'Serbia' 'Poland' 'Philippines' 'Bulgaria' 'Switzerland'\n",
      " 'India' 'Germany' 'Ireland' 'Italy' 'Ukraine' 'Australia' 'Brazil'\n",
      " 'Japan' 'Austria' 'Iran, Islamic Republic of...' 'France' 'Saudi Arabia'\n",
      " 'Romania' 'Turkey' 'Nepal' 'Algeria' 'Sweden' 'Netherlands' 'Croatia'\n",
      " 'Pakistan' 'Czech Republic' 'Republic of North Macedonia' 'Finland'\n",
      " 'Slovakia' 'Russian Federation' 'Greece' 'Israel' 'Belgium' 'Mexico'\n",
      " 'United Republic of Tanzania' 'Hungary' 'Argentina' 'Portugal'\n",
      " 'Sri Lanka' 'Latvia' 'China' 'Singapore' 'Lebanon' 'Spain' 'South Africa'\n",
      " 'Lithuania' 'Viet Nam' 'Dominican Republic' 'Indonesia' 'Kosovo'\n",
      " 'Morocco' 'Taiwan' 'Georgia' 'San Marino' 'Tunisia' 'Bangladesh'\n",
      " 'Nigeria' 'Liechtenstein' 'Denmark' 'Ecuador' 'Malaysia' 'Albania'\n",
      " 'Azerbaijan' 'Chile' 'Ghana' 'Peru' 'Bolivia' 'Egypt' 'Luxembourg'\n",
      " 'Montenegro' 'Cyprus' 'Paraguay' 'Kazakhstan' 'Slovenia' 'Jordan'\n",
      " 'Venezuela, Bolivarian Republic of...' 'Costa Rica' 'Jamaica' 'Thailand'\n",
      " 'Nicaragua' 'Myanmar' 'Republic of Korea' 'Rwanda'\n",
      " 'Bosnia and Herzegovina' 'Benin' 'El Salvador' 'Zimbabwe' 'Afghanistan'\n",
      " 'Estonia' 'Malta' 'Uruguay' 'Belarus' 'Colombia' 'Republic of Moldova'\n",
      " 'Isle of Man' 'Nomadic' 'New Zealand' 'Palestine' 'Armenia'\n",
      " 'United Arab Emirates' 'Maldives' 'Ethiopia' 'Fiji' 'Guatemala' 'Uganda'\n",
      " 'Turkmenistan' 'Mauritius' 'Kenya' 'Cuba' 'Gabon' 'Bahamas' 'South Korea'\n",
      " 'Iceland' 'Honduras' 'Hong Kong (S.A.R.)'\n",
      " \"Lao People's Democratic Republic\" 'Mongolia' 'Cambodia' 'Madagascar'\n",
      " 'Angola' 'Democratic Republic of the Congo' 'Syrian Arab Republic' 'Iraq'\n",
      " 'Namibia' 'Senegal' 'Kyrgyzstan' 'Zambia' 'Swaziland' \"Côte d'Ivoire\"\n",
      " 'Kuwait' 'Tajikistan' 'Burundi' 'Trinidad and Tobago' 'Mauritania'\n",
      " 'Sierra Leone' 'Panama' 'Somalia' 'North Korea' 'Dominica' 'Guyana'\n",
      " 'Togo' 'Oman' 'Barbados' 'Andorra'\n",
      " \"Democratic People's Republic of Korea\" 'Qatar' 'Sudan' 'Cameroon'\n",
      " 'Papua New Guinea' 'Bahrain' 'Yemen' 'Malawi' 'Burkina Faso'\n",
      " 'Congo, Republic of the...' 'Botswana' 'Guinea-Bissau' 'Mozambique'\n",
      " 'Central African Republic' 'Equatorial Guinea' 'Suriname' 'Belize'\n",
      " 'Libyan Arab Jamahiriya' 'Cape Verde' 'Brunei Darussalam' 'Bhutan'\n",
      " 'Guinea' 'Niger' 'Antigua and Barbuda' 'Mali' 'Samoa' 'Lesotho'\n",
      " 'Saint Kitts and Nevis' 'Monaco' 'Micronesia, Federated States of...'\n",
      " 'Haiti' 'Nauru' 'Liberia' 'Chad' 'Djibouti' 'Solomon Islands']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_299/3012335508.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Country\"] = df[\"Country\"].replace({\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Check unique values in the \"Country\" column\n",
    "print(df[\"Country\"].unique())\n",
    "\n",
    "# Standardize inconsistent country names\n",
    "df[\"Country\"] = df[\"Country\"].replace({\n",
    "    \"USA\": \"United States\",\n",
    "    \"U.S.A.\": \"United States\",\n",
    "    \"UK\": \"United Kingdom\",\n",
    "    \"U.K.\": \"United Kingdom\",\n",
    "    \"Deutschland\": \"Germany\",\n",
    "    \"FR\": \"France\"\n",
    "})\n",
    "\n",
    "# Verify standardization\n",
    "print(df[\"Country\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Primary/elementary school'\n",
      " 'Bachelor’s degree (B.A., B.S., B.Eng., etc.)'\n",
      " 'Master’s degree (M.A., M.S., M.Eng., MBA, etc.)'\n",
      " 'Some college/university study without earning a degree'\n",
      " 'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)'\n",
      " 'Professional degree (JD, MD, Ph.D, Ed.D, etc.)'\n",
      " 'Associate degree (A.A., A.S., etc.)' 'Something else']\n",
      "['Elementary School' \"Bachelor's Degree\" \"Master's Degree\" 'Some College'\n",
      " 'High School' 'Professional degree (JD, MD, Ph.D, Ed.D, etc.)'\n",
      " 'Associate degree (A.A., A.S., etc.)' 'Something else']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_299/1452030403.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"EdLevel\"] = df[\"EdLevel\"].replace({\n"
     ]
    }
   ],
   "source": [
    "# Check unique values in the \"EdLevel\" column\n",
    "print(df[\"EdLevel\"].unique())\n",
    "\n",
    "# Standardizing education levels\n",
    "df[\"EdLevel\"] = df[\"EdLevel\"].replace({\n",
    "    \"Bachelor’s degree (B.A., B.S., B.Eng., etc.)\": \"Bachelor's Degree\",\n",
    "    \"Master’s degree (M.A., M.S., M.Eng., MBA, etc.)\": \"Master's Degree\",\n",
    "    \"Some college/university study without earning a degree\": \"Some College\",\n",
    "    \"Primary/elementary school\": \"Elementary School\",\n",
    "    \"Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)\": \"High School\"\n",
    "})\n",
    "\n",
    "# Verify standardization\n",
    "print(df[\"EdLevel\"].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encoding Categorical Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>4.1 Encode the Employment column using one-hot encoding.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age RemoteWork  \\\n",
      "0           1  I am a developer by profession  Under 18 years old     Remote   \n",
      "1           2  I am a developer by profession     35-44 years old     Remote   \n",
      "2           3  I am a developer by profession     45-54 years old     Remote   \n",
      "3           4           I am learning to code     18-24 years old        NaN   \n",
      "4           5  I am a developer by profession     18-24 years old        NaN   \n",
      "\n",
      "    Check                                   CodingActivities  \\\n",
      "0  Apples                                              Hobby   \n",
      "1  Apples  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Apples  Hobby;Contribute to open-source projects;Other...   \n",
      "3  Apples                                                NaN   \n",
      "4  Apples                                                NaN   \n",
      "\n",
      "             EdLevel                                          LearnCode  \\\n",
      "0  Elementary School                             Books / Physical media   \n",
      "1  Bachelor's Degree  Books / Physical media;Colleague;On the job tr...   \n",
      "2    Master's Degree  Books / Physical media;Colleague;On the job tr...   \n",
      "3       Some College  Other online resources (e.g., videos, blogs, f...   \n",
      "4        High School  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  \\\n",
      "0                                                NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial   \n",
      "4  Technical documentation;Blogs;Written Tutorial...   \n",
      "\n",
      "                                             TechDoc  ...  \\\n",
      "0                                                NaN  ...   \n",
      "1  API document(s) and/or SDK document(s);User gu...  ...   \n",
      "2  API document(s) and/or SDK document(s);User gu...  ...   \n",
      "3                                                NaN  ...   \n",
      "4  API document(s) and/or SDK document(s);User gu...  ...   \n",
      "\n",
      "  Employment_Student, full-time;Not employed, but looking for work;Not employed, and not looking for work  \\\n",
      "0                                              False                                                        \n",
      "1                                              False                                                        \n",
      "2                                              False                                                        \n",
      "3                                              False                                                        \n",
      "4                                              False                                                        \n",
      "\n",
      "  Employment_Student, full-time;Not employed, but looking for work;Not employed, and not looking for work;Student, part-time  \\\n",
      "0                                              False                                                                           \n",
      "1                                              False                                                                           \n",
      "2                                              False                                                                           \n",
      "3                                              False                                                                           \n",
      "4                                              False                                                                           \n",
      "\n",
      "  Employment_Student, full-time;Not employed, but looking for work;Retired  \\\n",
      "0                                              False                         \n",
      "1                                              False                         \n",
      "2                                              False                         \n",
      "3                                              False                         \n",
      "4                                              False                         \n",
      "\n",
      "  Employment_Student, full-time;Not employed, but looking for work;Student, part-time  \\\n",
      "0                                              False                                    \n",
      "1                                              False                                    \n",
      "2                                              False                                    \n",
      "3                                              False                                    \n",
      "4                                              False                                    \n",
      "\n",
      "  Employment_Student, full-time;Student, part-time  \\\n",
      "0                                            False   \n",
      "1                                            False   \n",
      "2                                            False   \n",
      "3                                            False   \n",
      "4                                            False   \n",
      "\n",
      "  Employment_Student, full-time;Student, part-time;Employed, part-time  \\\n",
      "0                                              False                     \n",
      "1                                              False                     \n",
      "2                                              False                     \n",
      "3                                              False                     \n",
      "4                                              False                     \n",
      "\n",
      "  Employment_Student, full-time;Student, part-time;Retired  \\\n",
      "0                                              False         \n",
      "1                                              False         \n",
      "2                                              False         \n",
      "3                                              False         \n",
      "4                                              False         \n",
      "\n",
      "  Employment_Student, part-time  \\\n",
      "0                         False   \n",
      "1                         False   \n",
      "2                         False   \n",
      "3                         False   \n",
      "4                         False   \n",
      "\n",
      "  Employment_Student, part-time;Employed, part-time  \\\n",
      "0                                             False   \n",
      "1                                             False   \n",
      "2                                             False   \n",
      "3                                             False   \n",
      "4                                             False   \n",
      "\n",
      "  Employment_Student, part-time;Retired  \n",
      "0                                 False  \n",
      "1                                 False  \n",
      "2                                 False  \n",
      "3                                 False  \n",
      "4                                 False  \n",
      "\n",
      "[5 rows x 216 columns]\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# One-hot encode the \"Employment\" column\n",
    "df_encoded = pd.get_dummies(df, columns=[\"Employment\"], prefix=\"Employment\")\n",
    "\n",
    "# Display the first few rows to verify encoding\n",
    "print(df_encoded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.1 Identify columns with the highest number of missing values.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AINextMuch less integrated    57856\n",
      "AINextLess integrated         56674\n",
      "AINextNo change               46750\n",
      "AINextMuch more integrated    45867\n",
      "EmbeddedAdmired               42536\n",
      "                              ...  \n",
      "NEWSOSites                      629\n",
      "DevType                         601\n",
      "AISelect                        487\n",
      "YearsCode                       344\n",
      "LearnCode                       188\n",
      "Length: 107, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Count missing values per column\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Sort columns by highest missing values\n",
    "missing_values_sorted = missing_values.sort_values(ascending=False)\n",
    "\n",
    "# Display the columns with missing values\n",
    "print(missing_values_sorted[missing_values_sorted > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.2 Impute missing values in numerical columns (e.g., `ConvertedCompYearly`) with the mean or median.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns with missing values: ['CompTotal', 'WorkExp', 'JobSatPoints_1', 'JobSatPoints_4', 'JobSatPoints_5', 'JobSatPoints_6', 'JobSatPoints_7', 'JobSatPoints_8', 'JobSatPoints_9', 'JobSatPoints_10', 'JobSatPoints_11', 'ConvertedCompYearly', 'JobSat']\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Select numerical columns with missing values\n",
    "# Identify numerical columns with missing values\n",
    "num_cols_with_missing = df.select_dtypes(include=['number']).columns[df.select_dtypes(include=['number']).isnull().any()]\n",
    "print(\"Numerical columns with missing values:\", num_cols_with_missing.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5.3 Impute missing values in categorical columns (e.g., `RemoteWork`) with the most frequent value.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns with missing values: ['RemoteWork', 'CodingActivities', 'LearnCode', 'LearnCodeOnline', 'TechDoc', 'YearsCode', 'YearsCodePro', 'DevType', 'OrgSize', 'PurchaseInfluence', 'BuyNewTool', 'BuildvsBuy', 'TechEndorse', 'Currency', 'LanguageHaveWorkedWith', 'LanguageWantToWorkWith', 'LanguageAdmired', 'DatabaseHaveWorkedWith', 'DatabaseWantToWorkWith', 'DatabaseAdmired', 'PlatformHaveWorkedWith', 'PlatformWantToWorkWith', 'PlatformAdmired', 'WebframeHaveWorkedWith', 'WebframeWantToWorkWith', 'WebframeAdmired', 'EmbeddedHaveWorkedWith', 'EmbeddedWantToWorkWith', 'EmbeddedAdmired', 'MiscTechHaveWorkedWith', 'MiscTechWantToWorkWith', 'MiscTechAdmired', 'ToolsTechHaveWorkedWith', 'ToolsTechWantToWorkWith', 'ToolsTechAdmired', 'NEWCollabToolsHaveWorkedWith', 'NEWCollabToolsWantToWorkWith', 'NEWCollabToolsAdmired', 'OpSysPersonal use', 'OpSysProfessional use', 'OfficeStackAsyncHaveWorkedWith', 'OfficeStackAsyncWantToWorkWith', 'OfficeStackAsyncAdmired', 'OfficeStackSyncHaveWorkedWith', 'OfficeStackSyncWantToWorkWith', 'OfficeStackSyncAdmired', 'AISearchDevHaveWorkedWith', 'AISearchDevWantToWorkWith', 'AISearchDevAdmired', 'NEWSOSites', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOHow', 'SOComm', 'AISelect', 'AISent', 'AIBen', 'AIAcc', 'AIComplex', 'AIToolCurrently Using', 'AIToolInterested in Using', 'AIToolNot interested in Using', 'AINextMuch more integrated', 'AINextNo change', 'AINextMore integrated', 'AINextLess integrated', 'AINextMuch less integrated', 'AIThreat', 'AIEthics', 'AIChallenges', 'TBranch', 'ICorPM', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'Frequency_1', 'Frequency_2', 'Frequency_3', 'TimeSearching', 'TimeAnswering', 'Frustration', 'ProfessionalTech', 'ProfessionalCloud', 'ProfessionalQuestion', 'Industry', 'SurveyLength', 'SurveyEase']\n",
      "RemoteWork              0\n",
      "CodingActivities        0\n",
      "LearnCode               0\n",
      "LearnCodeOnline         0\n",
      "TechDoc                 0\n",
      "                       ..\n",
      "ProfessionalCloud       0\n",
      "ProfessionalQuestion    0\n",
      "Industry                0\n",
      "SurveyLength            0\n",
      "SurveyEase              0\n",
      "Length: 94, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "# Identify categorical columns with missing values\n",
    "cat_cols_with_missing = df.select_dtypes(include=['object']).columns[df.select_dtypes(include=['object']).isnull().any()]\n",
    "print(\"Categorical columns with missing values:\", cat_cols_with_missing.tolist())\n",
    "\n",
    "# Fill missing values with the most frequent value (mode)\n",
    "df[cat_cols_with_missing] = df[cat_cols_with_missing].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "# Verify if missing values are handled\n",
    "print(df[cat_cols_with_missing].isnull().sum())  # Should return all zeros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Feature Scaling and Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.1 Apply Min-Max Scaling to normalize the `ConvertedCompYearly` column.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (2.2.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m142.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m135.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ConvertedCompYearly  ConvertedCompYearly_MinMax\n",
      "count         2.343500e+04                23435.000000\n",
      "mean          8.615529e+04                    0.005300\n",
      "std           1.867570e+05                    0.011488\n",
      "min           1.000000e+00                    0.000000\n",
      "25%           3.271200e+04                    0.002012\n",
      "50%           6.500000e+04                    0.003998\n",
      "75%           1.079715e+05                    0.006642\n",
      "max           1.625660e+07                    1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_299/1949318009.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['ConvertedCompYearly_MinMax'] = scaler.fit_transform(df[['ConvertedCompYearly']])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply Min-Max Scaling\n",
    "df['ConvertedCompYearly_MinMax'] = scaler.fit_transform(df[['ConvertedCompYearly']])\n",
    "\n",
    "# Display summary statistics\n",
    "print(df[['ConvertedCompYearly', 'ConvertedCompYearly_MinMax']].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6.2 Log-transform the ConvertedCompYearly column to reduce skewness.</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ConvertedCompYearly  ConvertedCompYearly_Log\n",
      "0              65000.0                11.082158\n",
      "1              65000.0                11.082158\n",
      "2              65000.0                11.082158\n",
      "3              65000.0                11.082158\n",
      "4              65000.0                11.082158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_299/555813630.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['ConvertedCompYearly'].fillna(df['ConvertedCompYearly'].median(), inplace=True)\n",
      "/tmp/ipykernel_299/555813630.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['ConvertedCompYearly_Log'] = np.log1p(df['ConvertedCompYearly'])\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "import numpy as np\n",
    "df['ConvertedCompYearly'].fillna(df['ConvertedCompYearly'].median(), inplace=True)\n",
    "\n",
    "# Apply log transformation (log1p to handle zeros)\n",
    "df['ConvertedCompYearly_Log'] = np.log1p(df['ConvertedCompYearly'])\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df[['ConvertedCompYearly', 'ConvertedCompYearly_Log']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>7.1 Create a new column `ExperienceLevel` based on the `YearsCodePro` column:</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   YearsCodePro ExperienceLevel\n",
      "0           2.0    Intermediate\n",
      "1          17.0          Expert\n",
      "2          27.0          Expert\n",
      "3           2.0    Intermediate\n",
      "4           2.0    Intermediate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_299/3887412293.py:18: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['ExperienceLevel'] = df['YearsCodePro'].apply(categorize_experience)\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "df['YearsCodePro'] = pd.to_numeric(df['YearsCodePro'], errors='coerce')\n",
    "\n",
    "# Define experience levels based on years of professional coding\n",
    "def categorize_experience(years):\n",
    "    if pd.isna(years):\n",
    "        return 'Unknown'  # Handle missing values\n",
    "    elif years < 2:\n",
    "        return 'Beginner'\n",
    "    elif 2 <= years < 5:\n",
    "        return 'Intermediate'\n",
    "    elif 5 <= years < 10:\n",
    "        return 'Experienced'\n",
    "    else:\n",
    "        return 'Expert'\n",
    "\n",
    "# Apply the function to create the new column\n",
    "df['ExperienceLevel'] = df['YearsCodePro'].apply(categorize_experience)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df[['YearsCodePro', 'ExperienceLevel']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you:\n",
    "\n",
    "- Explored the dataset to identify inconsistencies and missing values.\n",
    "\n",
    "- Encoded categorical variables for analysis.\n",
    "\n",
    "- Handled missing values using imputation techniques.\n",
    "\n",
    "- Normalized and transformed numerical data to prepare it for analysis.\n",
    "\n",
    "- Engineered a new feature to enhance data interpretation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "1e8e234f19fd098e27b0518a87f18de690e1c51f1d3263d5690927d19971251e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
